{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "from Utils import parse_date, FMID, simple_date_pattern, year_pattern, parse_complex_date, ZIP, validate_zip_code\n",
    "\n",
    "# we should convert this notebook to open refine and then convert the steps to workflow using yes workflow\n",
    "\n",
    "S_DATE = \"Season1Date\"\n",
    "S_DATE_LIST = \"Season1DateList\"\n",
    "FILE_NAME = \"cl_farmers_s1date.csv\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"..\", \"dataset\", \"input\", \"farmers_market.csv\"))\n",
    "assert df[FMID].nunique() == df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up basic util data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "date = df[[FMID, S_DATE, ZIP]].dropna()\n",
    "date[S_DATE] = date[S_DATE].astype(str)\n",
    "\n",
    "date[ZIP] = date[ZIP].astype(str)\n",
    "# should have valid zip code\n",
    "print(\"invalid zip code row count-1\", len(date.loc[date[ZIP].apply(validate_zip_code) == False]))\n",
    "date = date.loc[date[ZIP].apply(validate_zip_code) == True]\n",
    "\n",
    "date = date.loc[date[S_DATE].str.contains(\" to \") == True] # should contain \"to\"\n",
    "date = date.loc[date[S_DATE].str.replace(\" \", \"\").str.isalpha() == False] # should contain some numeric data and should not be completely alphabetical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting simple and complex dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_simple = date.loc[date[S_DATE].apply(lambda x: re.search(simple_date_pattern, x))\\\n",
    "                    .apply(lambda x: x is not None)] # extracting simple dates  \n",
    "date_complex = date.loc[date[FMID].isin(date_simple[FMID]) != True] # extracting complex dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_complex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "date_simple[S_DATE_LIST] = date_simple[S_DATE].str.split(\" to \")\n",
    "date_simple[S_DATE_LIST] = date_simple.apply(parse_date, axis=1, args=(S_DATE,))\n",
    "date_simple = date_simple.loc[date_simple[S_DATE_LIST].apply(len) == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick only those FM id which have more that 2 dates in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# flattening\n",
    "date_simple[\"start\"] = [\"\"]*date_simple.shape[0]\n",
    "date_simple[\"end\"] = [\"\"]*date_simple.shape[0]\n",
    "def flatten(r: pd.Series):\n",
    "    r[\"start\"] = r[S_DATE_LIST][0]\n",
    "    r[\"end\"] = r[S_DATE_LIST][1]\n",
    "    return r\n",
    "date_simple = date_simple.apply(flatten, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save1 = date_simple[[FMID, \"start\", \"end\", ZIP]].reset_index(drop=True)\n",
    "display(df_to_save1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(date_complex)\n",
    "# we can simply ignore these FMIDs where there is no 4 digit year\n",
    "date_complex_without_year = date_complex.loc[date_complex[S_DATE]\\\n",
    "    .apply(lambda x: re.search(year_pattern, x)).apply(lambda x: x is None) == True]\n",
    "display(date_complex_without_year)\n",
    " # we need cleaning over these\n",
    "date_complex_with_year = date_complex.loc[date_complex[FMID].isin(date_complex_without_year[FMID]) == False]\n",
    "display(date_complex_with_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if date_complex_with_year.shape[0] > 0:\n",
    "    date_complex_with_year[S_DATE_LIST] = date_complex_with_year.apply(parse_complex_date, axis=1, args=(S_DATE,))\n",
    "\n",
    "display(date_complex_with_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if date_complex_with_year.shape[0] > 0:\n",
    "    date_complex_with_year = date_complex_with_year.loc[date_complex_with_year[S_DATE_LIST].apply(len) == 2]\n",
    "else:\n",
    "    date_complex_with_year = date_complex_with_year\n",
    "# flattening\n",
    "date_complex_with_year[\"start\"] = [\"\"]*date_complex_with_year.shape[0]\n",
    "date_complex_with_year[\"end\"] = [\"\"]*date_complex_with_year.shape[0]\n",
    "def flatten(r: pd.Series):\n",
    "    r[\"start\"] = r[S_DATE_LIST][0]\n",
    "    r[\"end\"] = r[S_DATE_LIST][1]\n",
    "    return r\n",
    "date_complex_with_year = date_complex_with_year.apply(flatten, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save2 = date_complex_with_year[[FMID, \"start\", \"end\", ZIP]]\n",
    "df_to_save2 = df_to_save2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([df_to_save1, df_to_save2]).to_csv(os.path.join(\"..\", \"dataset\", \"output\", FILE_NAME))\n",
    "conn = sqlite3.connect(f\"{DATASET_LOC}/../database/farmers_market.db\")\n",
    "pd.concat([df_to_save1, df_to_save2]).to_sql(\"fm_seasons_dates\", conn, if_exists=\"replace\")\n",
    "conn.cursor().execute(\n",
    "    \"\"\"\n",
    "    select count(*) from farmers_market\n",
    "    \"\"\").fetchall()\n",
    "# seasons_date=pd.read_csv(f\"{DATASET_LOC}/input/seasons/cl_farmers_s1date.csv\")\n",
    "# seasons_date.to_sql(\"fm_seasons_dates\", conn, if_exists=\"replace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('illi_MS_DS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a82d6eb3804a92444605d7a5aa99dc8a820299debc222bc81f709e34341d1d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}